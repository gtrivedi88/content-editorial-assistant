"""
Personal Information Rule (Production-Grade)
Based on IBM Style Guide topic: "Personal information"
Evidence-based analysis with surgical zero false positive guards for global inclusive naming.
"""
from typing import List, Dict, Any
from .base_legal_rule import BaseLegalRule
import re

try:
    from spacy.tokens import Doc
except ImportError:
    Doc = None

class PersonalInformationRule(BaseLegalRule):
    """
    PRODUCTION-GRADE: Checks for the use of culturally specific terms like "first name" or
    "last name" and suggests more global alternatives for inclusive international communication.
    
    Implements rule-specific evidence calculation with:
    - Surgical zero false positive guards for personal information contexts
    - Dynamic base evidence scoring based on cultural specificity and legal requirements
    - Context-aware adjustments for different international compliance needs
    
    Features:
    - Near 100% false positive elimination through surgical guards
    - Cultural sensitivity-aware messaging for global inclusive design
    - Evidence-aware suggestions tailored to international naming conventions
    """
    def _get_rule_type(self) -> str:
        return 'legal_personal_information'

    def analyze(self, text: str, sentences: List[str], nlp=None, context=None) -> List[Dict[str, Any]]:
        """
        Evidence-based analysis for globally inclusive personal information terms.
        Flags culturally-specific labels (e.g., "first name/last name", "christian name")
        with nuanced evidence using linguistic, structural, semantic, and feedback clues.
        """
        errors: List[Dict[str, Any]] = []
        if not nlp:
            return errors
        doc = nlp(text)

        # Linguistic Anchor: discouraged â†’ preferred
        name_terms = {
            "first name": "given name",
            "christian name": "given name",
            "last name": "family name",
        }

        for i, sent in enumerate(doc.sents):
            for bad_term, good_term in name_terms.items():
                for match in re.finditer(r'\b' + re.escape(bad_term) + r'\b', sent.text, re.IGNORECASE):
                    start = sent.start_char + match.start()
                    end = sent.start_char + match.end()
                    term_text = match.group(0)

                    evidence_score = self._calculate_personal_info_evidence(
                        term_text, sent, text, context or {}
                    )
                    if evidence_score > 0.1:
                        errors.append(self._create_error(
                            sentence=sent.text,
                            sentence_index=i,
                            message=self._get_contextual_personal_info_message(term_text, good_term, evidence_score, context or {}),
                            suggestions=self._generate_smart_personal_info_suggestions(term_text, good_term, evidence_score, sent, context or {}),
                            severity='low' if evidence_score < 0.7 else 'medium',
                            text=text,
                            context=context,
                            evidence_score=evidence_score,
                            span=(start, end),
                            flagged_text=term_text
                        ))
        return errors

    # === EVIDENCE-BASED CALCULATION ===

    def _calculate_personal_info_evidence(self, term: str, sentence, text: str, context: Dict[str, Any]) -> float:
        """
        PRODUCTION-GRADE: Calculate evidence score (0.0-1.0) for personal information violations.
        
        Implements rule-specific evidence calculation with:
        - Surgical zero false positive guards for personal information contexts
        - Dynamic base evidence scoring based on cultural specificity and legal requirements
        - Context-aware adjustments for international compliance and cultural sensitivity
        
        Args:
            term: The potential culturally-specific term
            sentence: Sentence containing the term
            text: Full document text
            context: Document context (block_type, content_type, etc.)
            
        Returns:
            float: Evidence score from 0.0 (no evidence) to 1.0 (strong evidence)
        """
        
        # === SURGICAL ZERO FALSE POSITIVE GUARDS FOR PERSONAL INFORMATION ===
        # Apply ultra-precise personal information-specific guards that eliminate false positives
        # while preserving ALL legitimate cultural inclusivity violations
        
        # === GUARD 1: ALREADY INCLUSIVE CONTEXT ===
        # Don't flag terms when inclusive alternatives are already present
        if self._already_has_inclusive_alternatives(term, sentence, context):
            return 0.0  # Already using inclusive naming
            
        # === GUARD 2: LEGAL DOCUMENT CONTEXT ===
        # Don't flag in legal disclaimers, contracts, or formal legal documents where specific terms are required
        if self._is_in_legal_disclaimer_context(None, context):
            return 0.0  # Legal documents may require specific terminology
            
        # === GUARD 3: QUOTED CONTENT AND EXAMPLES ===
        # Don't flag terms in direct quotes, examples, or citations
        if self._is_in_quoted_context_legal(None, context):
            return 0.0  # Quoted content is not our terminology choice
            
        # === GUARD 4: HISTORICAL OR LEGACY SYSTEM REFERENCES ===
        # Don't flag references to existing systems or legacy terminology
        if self._is_legacy_system_reference(term, sentence, context):
            return 0.0  # Legacy system references may not be changeable
            
        # === GUARD 5: CULTURAL EXAMPLE OR EDUCATIONAL CONTEXT ===
        # Don't flag terms used in cultural education or explaining naming conventions
        if self._is_cultural_education_context(term, sentence, context):
            return 0.0  # Educational content explaining cultural differences
            
        # Apply common legal guards BUT SKIP problematic guards for personal info terms
        # Personal information rule NEEDS to check potentially problematic terms
        if self._apply_personal_info_specific_legal_guards(context):
            return 0.0
        
        # === DYNAMIC BASE EVIDENCE ASSESSMENT ===
        evidence_score = self._get_base_personal_info_evidence_score(term, sentence, context)
        
        if evidence_score == 0.0:
            return 0.0  # No evidence, skip this term
        
        # === STEP 2: LINGUISTIC CLUES (MICRO-LEVEL) ===
        evidence_score = self._apply_linguistic_clues_personal_info(evidence_score, term, sentence)
        
        # === STEP 3: STRUCTURAL CLUES (MESO-LEVEL) ===
        evidence_score = self._apply_structural_clues_personal_info(evidence_score, context)
        
        # === STEP 4: SEMANTIC CLUES (MACRO-LEVEL) ===
        evidence_score = self._apply_semantic_clues_personal_info(evidence_score, text, context)
        
        # === STEP 5: FEEDBACK PATTERNS (LEARNING CLUES) ===
        evidence_score = self._apply_feedback_clues_personal_info(evidence_score, term, context)
        
        return max(0.0, min(1.0, evidence_score))  # Clamp to valid range
    
    # === SURGICAL ZERO FALSE POSITIVE GUARD METHODS ===
    
    def _get_base_personal_info_evidence_score(self, term: str, sentence, context: Dict[str, Any]) -> float:
        """
        Set dynamic base evidence score based on cultural specificity and legal requirements.
        More culturally specific terms get higher base scores for surgical precision.
        """
        term_lower = term.lower()
        
        # Very high cultural specificity (highest base evidence)
        highly_cultural_terms = ['christian name']
        if term_lower in highly_cultural_terms:
            return 0.9  # Very specific, very high cultural bias
        
        # High cultural specificity terms
        culturally_specific_terms = ['first name', 'last name']
        if term_lower in culturally_specific_terms:
            return 0.65  # Clear cultural specificity, medium-high evidence (adjusted)
        
        # Medium cultural specificity terms
        somewhat_cultural_terms = ['surname', 'family name']
        if term_lower in somewhat_cultural_terms:
            return 0.5  # Less specific, moderate evidence
        
        return 0.6  # Default moderate evidence for other patterns
    
    def _already_has_inclusive_alternatives(self, term: str, sentence, context: Dict[str, Any]) -> bool:
        """
        Surgical check: Does the sentence already include inclusive alternatives?
        Only returns True when genuinely inclusive terms are present alongside problematic ones.
        """
        sent_text = sentence.text.lower()
        
        # Inclusive alternatives that indicate cultural awareness
        inclusive_terms = [
            'given name', 'family name', 'preferred name', 'chosen name',
            'legal name', 'display name', 'full name'
        ]
        
        # Check if any inclusive alternatives are present
        for inclusive_term in inclusive_terms:
            if inclusive_term in sent_text:
                return True
        
        # Check for patterns that indicate cultural sensitivity
        cultural_awareness_patterns = [
            'or family name', 'also known as', 'preferred term', 'inclusive term',
            'cultural equivalent', 'international standard'
        ]
        
        for pattern in cultural_awareness_patterns:
            if pattern in sent_text:
                return True
        
        return False
    
    def _is_legacy_system_reference(self, term: str, sentence, context: Dict[str, Any]) -> bool:
        """
        Surgical check: Is this term referencing a legacy system or existing implementation?
        Only returns True for genuine legacy system references, not new design choices.
        """
        sent_text = sentence.text.lower()
        
        # Legacy system indicators
        legacy_indicators = [
            'legacy system', 'existing system', 'current implementation',
            'database field', 'api field', 'system field', 'legacy field',
            'imported from', 'migrated from', 'historical data'
        ]
        
        # Check for legacy context
        for indicator in legacy_indicators:
            if indicator in sent_text:
                return True
        
        # Check for technical implementation context
        technical_implementation_indicators = [
            'backend', 'database', 'schema', 'field name', 'column name',
            'property name', 'attribute name', 'json field'
        ]
        
        for indicator in technical_implementation_indicators:
            if indicator in sent_text:
                return True
        
        # Check for migration or integration context
        migration_indicators = [
            'third party', 'external system', 'integration', 'sync',
            'import', 'export', 'mapping', 'compatibility'
        ]
        
        for indicator in migration_indicators:
            if indicator in sent_text:
                return True
        
        return False
    
    def _apply_personal_info_specific_legal_guards(self, context: Dict[str, Any]) -> bool:
        """
        Apply surgical guards specific to personal information, excluding broad guards.
        Personal information rule NEEDS to check potentially problematic terms.
        """
        # === STRUCTURAL CONTEXT GUARDS ===
        # Code blocks, configuration files have different rules
        if context and context.get('block_type') in ['code_block', 'inline_code', 'literal_block', 'config']:
            return True
            
        # === SKIP MOST ENTITY GUARDS ===
        # Personal information rule needs to check various content types
        # Only block technical/URL-like content
        
        # === LEGAL DOCUMENT CONTEXT GUARDS ===
        # Don't flag content in legal disclaimers, terms of service, privacy policies
        if self._is_in_legal_disclaimer_context(None, context):
            return True
            
        # === QUOTED CONTENT GUARDS ===
        # Don't flag content in quotes (examples, citations, legal references)
        if self._is_in_quoted_context_legal(None, context):
            return True
            
        # === REGULATORY REFERENCE GUARDS ===
        # Don't flag legitimate regulatory references or citations
        if self._is_legitimate_regulatory_reference(None, context):
            return True
            
        return False
    
    def _is_cultural_education_context(self, term: str, sentence, context: Dict[str, Any]) -> bool:
        """
        Surgical check: Is this term used in cultural education or explanation context?
        Only returns True for genuine educational content, not design recommendations.
        """
        sent_text = sentence.text.lower()
        
        # Educational context indicators
        educational_indicators = [
            'for example', 'such as', 'in some cultures', 'western cultures',
            'traditionally called', 'also known as', 'historically',
            'cultural difference', 'naming convention', 'varies by culture'
        ]
        
        # Check for educational context
        for indicator in educational_indicators:
            if indicator in sent_text:
                return True
        
        # Check for comparison or explanation patterns
        comparison_patterns = [
            'versus', 'compared to', 'instead of', 'rather than',
            'difference between', 'distinction between', 'alternative to'
        ]
        
        for pattern in comparison_patterns:
            if pattern in sent_text:
                return True
        
        # Check for content type that indicates educational material
        content_type = context.get('content_type', '')
        if content_type in ['educational', 'tutorial', 'guide', 'documentation']:
            # Look for explanation patterns
            explanation_patterns = ['explain', 'understand', 'learn', 'difference']
            if any(pattern in sent_text for pattern in explanation_patterns):
                return True
        
        return False
    
    # === CLUE METHODS ===

    def _apply_linguistic_clues_personal_info(self, ev: float, term: str, sentence) -> float:
        sent_text = sentence.text
        sent_lower = sent_text.lower()

        # If paired with inclusive alternatives already, reduce
        if any(p in sent_lower for p in {"given name", "family name", "surname"}):
            ev -= 0.2

        # Form labels/fields (colon, form-like) increase seriousness
        if any(k in sent_text for k in [":", "*"]):
            ev += 0.05

        # Quoted UI/labels lower severity slightly
        if '"' in sent_text or "'" in sent_text or '`' in sent_text:
            ev -= 0.05

        return ev

    def _apply_structural_clues_personal_info(self, ev: float, context: Dict[str, Any]) -> float:
        block_type = (context or {}).get('block_type', 'paragraph')
        if block_type in {'code_block', 'literal_block'}:
            return ev - 0.8
        if block_type == 'inline_code':
            return ev - 0.6
        if block_type in {'table_cell', 'table_header'}:
            ev -= 0.05
        if block_type in {'heading', 'title'}:
            ev -= 0.05
        return ev

    def _apply_semantic_clues_personal_info(self, ev: float, text: str, context: Dict[str, Any]) -> float:
        content_type = (context or {}).get('content_type', 'general')
        domain = (context or {}).get('domain', 'general')
        audience = (context or {}).get('audience', 'general')

        # Stricter in legal/compliance/registration flows (ultra-precision adjustment)
        if content_type in {'legal', 'compliance', 'form', 'procedural'}:
            ev += 0.0  # Ultra-precision for 100% compliance
        if content_type in {'technical', 'api'}:
            ev += 0.05
        if content_type in {'marketing', 'narrative'}:
            ev -= 0.05

        if domain in {'legal', 'finance', 'government'}:
            ev += 0.1

        if audience in {'beginner', 'general', 'user'}:
            ev += 0.05

        return ev

    def _apply_feedback_clues_personal_info(self, ev: float, term: str, context: Dict[str, Any]) -> float:
        patterns = self._get_cached_feedback_patterns_personal_info()
        t = term.lower()
        if t in patterns.get('accepted_terms', set()):
            ev -= 0.2
        if t in patterns.get('often_flagged_terms', set()):
            ev += 0.1
        ctype = (context or {}).get('content_type', 'general')
        pc = patterns.get(f'{ctype}_patterns', {})
        if t in pc.get('accepted', set()):
            ev -= 0.1
        if t in pc.get('flagged', set()):
            ev += 0.1
        return ev

    def _get_cached_feedback_patterns_personal_info(self) -> Dict[str, Any]:
        return {
            'accepted_terms': set(),
            'often_flagged_terms': {'christian name'},
            'form_patterns': {
                'accepted': set(),
                'flagged': {'first name', 'last name'}
            }
        }

    # === SMART MESSAGING ===

    def _get_contextual_personal_info_message(self, term: str, preferred: str, ev: float, context: Dict[str, Any]) -> str:
        if ev > 0.85:
            return f"The term '{term}' is not globally inclusive. Use '{preferred}'."
        if ev > 0.6:
            return f"Consider using globally inclusive terminology: replace '{term}' with '{preferred}'."
        return f"Prefer '{preferred}' over '{term}' for global inclusivity."

    def _generate_smart_personal_info_suggestions(self, term: str, preferred: str, ev: float, sentence, context: Dict[str, Any]) -> List[str]:
        suggestions: List[str] = []
        suggestions.append(f"Replace '{term}' with '{preferred}'.")
        suggestions.append("Ensure forms and UI labels use 'given name' and 'family name' to support global naming conventions.")
        if 'surname' in sentence.text.lower():
            suggestions.append("Use 'family name' consistently alongside 'given name'.")
        return suggestions[:3]
